summary(df_height)
# Get the number of dimensions or dataset size
dim(df_height)
par(mfrow = c(2,2))
plot(df_height$father, df_height$childHeight)
plot(df_height$mother, df_height$childHeight)
plot(df_height$midparentHeight, df_height$childHeight)
##### FEATURE ENGINEERING ----
# Understand the Feature Engineered variable
# mideparentHeight = (father + 1.08*mother)/2
m0 <- lm(midparentHeight ~ father + mother, data = df_height)
summary(m0)
# Copy dataset for EDA purposes
df_height_eda <- df_height
# Create a new column pred for prediction
df_height_eda$pred <- predict(m0, newdata = df_height_eda)
# Plot the predictions (on the x-axis) against the outcome (midparentHeight)
ggplot(df_height_eda, aes(x = pred, y = midparentHeight)) +
geom_point() +
geom_abline()
plot(m0) # An example of the ideal plot
##### MODEL TRAINING ----
#### Split dataset to train/test data ----
# Get the number of rows by using nrow to and store to N
N <- nrow(df_height)
# Show N
N
# Get 70% of N to split the dataset into 70% for training and the remaining 30% for testing
# Use round() to get an integer
# Enclosing the whole variable declaration will print the value of the variable
(smp_size <- floor(0.70 * N))
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Set the seed to make your partition reproducible
set.seed(123)
train_indeces <- sample(seq_len(N), size = smp_size)
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Use nrow() to examine df_height_train_train and df_height_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_height_train stats summary
summary(df_train)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight)
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
childHeight_pred <- 18.09189 + 0.70359 * 69.020
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- cor(df_train$pred, df_train$childHeight)^2
rsq_test <- cor(df_test$pred, df_test$childHeight)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
cv_results <- train(childHeight ~ midparentHeight, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
#### Visualize the linear regression model
plot(height_model)
par(mfrow = c(2,2))
#### Visualize the linear regression model
plot(height_model)
library(performance)
# Performance package:
performance::check_model(model_wage1)
library(performance)
# Performance package:
performance::check_model(height_model)
##### IMPROVING THE MODELS
# Option 1: Transform childHeight (logarithmic)
df_height_transformed <- df_height
df_height_transformed$childHeight_log <- log(df_height_transformed$childHeight)
# Train model on transformed data
height_model_transformed <- lm(childHeight_log ~ midparentHeight, data = df_train_transformed)
# Option 2: Weighted least squares
library(car)
##### IMPROVING THE MODELS
# Option 1: Transform childHeight (logarithmic)
df_height_transformed <- df_height
df_height_transformed$childHeight_log <- log(df_height_transformed$childHeight)
# Train model on transformed data
height_model_transformed <- lm(childHeight_log ~ midparentHeight, data = df_train_transformed)
##### IMPROVING THE MODELS
# Option 1: Transform childHeight (logarithmic)
df_height_transformed <- df_height
df_height_transformed$childHeight_log <- log(df_height_transformed$childHeight)
# Train model on transformed data
height_model_transformed_transformed <- lm(childHeight_log ~ midparentHeight, data = df_train_transformed)
##### IMPROVING THE MODELS
# Option 1: Transform childHeight (logarithmic)
df_height_transformed <- df_height
df_height_transformed$childHeight_log <- log(df_height_transformed$childHeight)
df_train_transformed <- df_height_transformed[train_indeces, ]
df_test_transformed <- df_height_transformed[-train_indeces, ]
# Train model on transformed data
height_model_transformed_transformed <- lm(childHeight_log ~ midparentHeight, data = df_train_transformed)
# Evaluate model using Holdout Validation ----
df_train_transformed$pred <- predict(height_model_transformed, newdata = df_train_transformed)
# Train model on transformed data
height_model_transformed <- lm(childHeight_log ~ midparentHeight, data = df_train_transformed)
# Evaluate model using Holdout Validation ----
df_train_transformed$pred <- predict(height_model_transformed, newdata = df_train_transformed)
df_test_transformed$pred <- predict(height_model_transformed, newdata = df_test_transformed)
# Evaluation metrics
rmse_train <- RMSE(df_train_transformed$pred, df_train_transformed$childHeight)
rmse_test <- RMSE(df_test_transformed$pred, df_test_transformed$childHeight)
rsq_train <- cor(df_train_transformed$pred, df_train_transformed$childHeight)^2
rsq_test <- cor(df_test_transformed$pred, df_test_transformed$childHeight)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test_transformed, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
cv_results <- train(childHeight ~ midparentHeight, data = df_height_transformed, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
# Option 2: Weighted least squares
install.packages("car")
install.packages("car")
# Option 2: Weighted least squares
# install.packages("car")
library(car)
weights <- 1 / (df_train$childHeight^2)  # Example weighting scheme (adjust as needed)
height_model_transformed_weighted <- lm(childHeight ~ midparentHeight, data = df_train, weights = weights)
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model_transformed_weighted, newdata = df_train)
df_test$pred <- predict(height_model_transformed_weighted, newdata = df_test)
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- cor(df_train$pred, df_train$childHeight)^2
rsq_test <- cor(df_test$pred, df_test$childHeight)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
cv_results <- train(childHeight ~ midparentHeight, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
# Option 3: Polynomial regression
height_model_transformed_poly <- lm(childHeight ~ midparentHeight + I(midparentHeight^2), data = df_train)
# Evaluate and compare with original model
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model_transformed_poly, newdata = df_train)
df_test$pred <- predict(height_model_transformed_poly, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- cor(df_train$pred, df_train$childHeight)^2
rsq_test <- cor(df_test$pred, df_test$childHeight)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
cv_results <- train(childHeight ~ midparentHeight, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
##### PRELIMINARY DATA ANALYSIS ----
# For crestarting environment
rm(list = ls())
##### Load packages ----
# GaltonFamilies dataset can be obtained from this package
# install.packages("HistData")
library(HistData)
##### Import data and store to df_height ----
data(GaltonFamilies)
# Explore more about the dataset
?GaltonFamilies
# Store GaltonFamilies dataset to df_height
df_height <- GaltonFamilies
# View dataset
View(df_height)
# View the statistical summary of the height dataset
summary(df_height)
# Get the number of dimensions or dataset size
dim(df_height)
par(mfrow = c(2,2))
plot(df_height$father, df_height$childHeight)
plot(df_height$mother, df_height$childHeight)
plot(df_height$midparentHeight, df_height$childHeight)
##### FEATURE ENGINEERING ----
# Understand the Feature Engineered variable
# mideparentHeight = (father + 1.08*mother)/2
m0 <- lm(midparentHeight ~ father + mother, data = df_height)
summary(m0)
# Copy dataset for EDA purposes
df_height_eda <- df_height
# Create a new column pred for prediction
df_height_eda$pred <- predict(m0, newdata = df_height_eda)
# Plot the predictions (on the x-axis) against the outcome (midparentHeight)
ggplot(df_height_eda, aes(x = pred, y = midparentHeight)) +
geom_point() +
geom_abline()
# INTERPRETATION:
# We can predict midparentHeight witt this equation:
# midparentHeight = 0.5 (father) + 0.54 (mother)
# PERFECT FIT
par(mfrow = c(2,2))
plot(m0)
##### MODEL TRAINING ----
#### Split dataset to train/test data ----
# Get the number of rows by using nrow to and store to N
N <- nrow(df_height)
# Show N
N
# Get 70% of N to split the dataset into 70% for training and the remaining 30% for testing
# Use round() to get an integer
# Enclosing the whole variable declaration will print the value of the variable
(smp_size <- floor(0.70 * N))
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Use nrow() to examine df_height_train_train and df_height_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_height_train stats summary
summary(df_train)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight)
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
childHeight_pred <- 18.09189 + 0.70359 * 69.020
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- cor(df_train$pred, df_train$childHeight)^2
rsq_test <- cor(df_test$pred, df_test$childHeight)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
cv_results <- train(childHeight ~ midparentHeight, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
#### Visualize the linear regression model
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight + gender)
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
childHeight_pred <- 18.09189 + 0.70359 * 69.020
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- cor(df_train$pred, df_train$childHeight)^2
rsq_test <- cor(df_test$pred, df_test$childHeight)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
set.seed(143)
cv_results <- train(childHeight ~ midparentHeight, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
##### VISUALIZE THE MODEL ----
par(mfrow = c(2,2))
plot(height_model)
# Performance package:
performance::check_model(height_model)
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Child Height (Test Set)")
##### PRELIMINARY DATA ANALYSIS ----
# For crestarting environment
rm(list = ls())
##### Load packages ----
# GaltonFamilies dataset can be obtained from this package
# install.packages("HistData")
install.packages("woodlridge")
library(wooldridge)
##### Import data and store to df_height ----
data(wage1)
# Explore more about the dataset
?wage1
# Store GaltonFamilies dataset to df_height
df_height <- wage1
# View dataset
View(df_height)
# View the statistical summary of the height dataset
summary(df_height)
# Get the number of dimensions or dataset size
dim(df_height)
par(mfrow = c(2,2))
##### MODEL TRAINING ----
#### Split dataset to train/test data ----
# Get the number of rows by using nrow to and store to N
N <- nrow(df_height)
# Show N
N
# Get 70% of N to split the dataset into 70% for training and the remaining 30% for testing
# Use round() to get an integer
# Enclosing the whole variable declaration will print the value of the variable
(smp_size <- floor(0.70 * N))
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Use nrow() to examine df_height_train_train and df_height_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_height_train stats summary
summary(df_train)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- wage ~ educ)
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
childHeight_pred <- 18.09189 + 0.70359 * 69.020
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- cor(df_train$pred, df_train$childHeight)^2
# Evaluation metrics
rmse_train <- RMSE(df_train$pred, df_train$wage)
rmse_test <- RMSE(df_test$pred, df_test$wage)
rsq_train <- cor(df_train$pred, df_train$wage)^2
rsq_test <- cor(df_test$pred, df_test$wage)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = wage)) +
geom_point() +
geom_abline() +
geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
set.seed(143)
cv_results <- train(childHeight ~ educ, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
cv_results <- train(childHeight ~ educ, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_results <- train(wage ~ educ, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
