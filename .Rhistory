# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Use nrow() to examine df_height_train_train and df_height_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_height_train stats summary
summary(df_train)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight)
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
# Use summary() to examine the model
summary(height_model)
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
# For restarting environment
rm(list = ls())
# Set working directory
PWD <- file.path(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd(PWD)
##### Load packages ----
# GaltonFamilies dataset can be obtained from this package
# install.packages("HistData")
library(HistData)
library(tidyverse)
##### Import data and store to df_height ----
data(GaltonFamilies)
# Explore more about the dataset
?GaltonFamilies
# Store GaltonFamilies dataset to df_height
df_height <- GaltonFamilies
# View dataset
View(df_height)
# View the statistical summary of the height dataset
summary(df_height)
# Get the number of dimensions or dataset size
dim(df_height)
##### EDA ----
# Step 2: Data exploration
par(mfrow = c(2,2))
plot(df_height$father, df_height$childHeight)
plot(df_height$mother, df_height$childHeight)
plot(df_height$midparentHeight, df_height$childHeight)
##### FEATURE ENGINEERING ----
# Understand the Feature Engineered variable
# midparentHeight = (father + 1.08*mother)/2
m0 <- lm(midparentHeight ~ father + mother, data = df_height)
summary(m0)
# Copy dataset for EDA purposes
df_height_eda <- df_height
# Create a new column pred for prediction
df_height_eda$pred <- predict(m0, newdata = df_height_eda)
# Plot the predictions (on the x-axis) against the outcome (midparentHeight)
ggplot(df_height_eda, aes(x = pred, y = midparentHeight)) +
geom_point() +
geom_abline()
##### MODEL TRAINING ----
#### Split dataset to train/test data ----
# Get the number of rows by using nrow to and store to N
N <- nrow(df_height)
# Show N
N
# Get 70% of N to split the dataset into 70% for training and the remaining 30% for testing
# Use floor() to get an integer
# Enclosing the whole variable declaration will print the value of the variable
(smp_size <- floor(0.70 * N))
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Use nrow() to examine df_height_train_train and df_height_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_height_train stats summary
summary(df_train)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight)
# Step 3: Estimate a regression model
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
childHeight_pred <- 18.09189 + 0.70359 * 69.020
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
data.table::fwrite(df_train, "train_prediction.csv")
data.table::fwrite(df_test, "test_prediction.csv")
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
mae_train <- mean(abs(df_train$pred - df_train$childHeight))
mae_test <- mean(abs(df_test$pred - df_test$childHeight))
mse_train <- mean((df_train$pred - df_train$childHeight)^2)
mse_test <- mean((df_test$pred - df_test$childHeight)^2)
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- 1 - sum((df_train$pred - df_train$childHeight)^2) / sum((df_train$childHeight - mean(df_train$childHeight))^2)
rsq_test <- 1 - sum((df_test$pred - df_test$childHeight)^2) / sum((df_test$childHeight - mean(df_test$childHeight))^2)
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
# geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# For restarting environment
rm(list = ls())
# Set working directory
PWD <- file.path(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd(PWD)
##### Load packages ----
# GaltonFamilies dataset can be obtained from this package
# install.packages("HistData")
library(HistData)
library(tidyverse)
##### Import data and store to df_height ----
data(GaltonFamilies)
# Explore more about the dataset
?GaltonFamilies
# Store GaltonFamilies dataset to df_height
df_height <- GaltonFamilies
# View dataset
View(df_height)
# View the statistical summary of the height dataset
summary(df_height)
# Get the number of dimensions or dataset size
dim(df_height)
##### EDA ----
# Step 2: Data exploration
par(mfrow = c(2,2))
plot(df_height$father, df_height$childHeight)
plot(df_height$mother, df_height$childHeight)
plot(df_height$midparentHeight, df_height$childHeight)
##### FEATURE ENGINEERING ----
# Understand the Feature Engineered variable
# midparentHeight = (father + 1.08*mother)/2
m0 <- lm(midparentHeight ~ father + mother, data = df_height)
summary(m0)
# Copy dataset for EDA purposes
df_height_eda <- df_height
# Create a new column pred for prediction
df_height_eda$pred <- predict(m0, newdata = df_height_eda)
# Plot the predictions (on the x-axis) against the outcome (midparentHeight)
ggplot(df_height_eda, aes(x = pred, y = midparentHeight)) +
geom_point() +
geom_abline()
##### MODEL TRAINING ----
#### Split dataset to train/test data ----
# Get the number of rows by using nrow to and store to N
N <- nrow(df_height)
# Show N
N
# Get 70% of N to split the dataset into 70% for training and the remaining 30% for testing
# Use floor() to get an integer
# Enclosing the whole variable declaration will print the value of the variable
(smp_size <- floor(0.70 * N))
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Use nrow() to examine df_height_train_train and df_height_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_height_train stats summary
summary(df_train)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight)
# Step 3: Estimate a regression model
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
# Use summary() to examine the model
summary(height_model)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight + gender)
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
childHeight_pred <- 18.09189 + 0.70359 * 69.020
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
mae_train <- mean(abs(df_train$pred - df_train$childHeight))
mae_test <- mean(abs(df_test$pred - df_test$childHeight))
mse_train <- mean((df_train$pred - df_train$childHeight)^2)
mse_test <- mean((df_test$pred - df_test$childHeight)^2)
rmse_train <- RMSE(df_train$pred, df_train$childHeight)
rmse_test <- RMSE(df_test$pred, df_test$childHeight)
rsq_train <- cor(df_train$pred, df_train$childHeight)^2
rsq_test <- cor(df_test$pred, df_test$childHeight)^2
# Plot the predictions (on the x-axis) against the outcome (childHeight) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = childHeight)) +
geom_point() +
geom_abline() +
geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Child Height (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
set.seed(143)
cv_results <- train(fmla, data = df_height, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_mae <- cv_results$results$MAE
cv_mse <- cv_results$results$MSE
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("MAE (Train):", mae_train, "\n")
cat("MAE (Test):", mae_test, "\n")
cat("MSE (Train):", mse_train, "\n")
cat("MSE (Test):", mse_test, "\n\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("MAE (CV):", mean(cv_mae), "\n")
cat("MSE (CV):", mean(cv_mse), "\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
##### VISUALIZE THE MODEL ----
par(mfrow = c(2,2))
plot(height_model)
# Use summary() to examine the model
summary(height_model)
# For restarting environment
rm(list = ls())
# Set working directory
PWD <- file.path(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd(PWD)
##### Load packages ----
# GaltonFamilies dataset can be obtained from this package
# install.packages("HistData")
library(HistData)
library(tidyverse)
##### Import data and store to df_height ----
data(GaltonFamilies)
# Explore more about the dataset
?GaltonFamilies
# Store GaltonFamilies dataset to df_height
df_height <- GaltonFamilies
# View dataset
View(df_height)
# View the statistical summary of the height dataset
summary(df_height)
# Get the number of dimensions or dataset size
dim(df_height)
##### EDA ----
# Step 2: Data exploration
par(mfrow = c(2,2))
plot(df_height$father, df_height$childHeight)
plot(df_height$mother, df_height$childHeight)
plot(df_height$midparentHeight, df_height$childHeight)
##### FEATURE ENGINEERING ----
# Understand the Feature Engineered variable
# midparentHeight = (father + 1.08*mother)/2
m0 <- lm(midparentHeight ~ father + mother, data = df_height)
summary(m0)
# Copy dataset for EDA purposes
df_height_eda <- df_height
# Create a new column pred for prediction
df_height_eda$pred <- predict(m0, newdata = df_height_eda)
# Plot the predictions (on the x-axis) against the outcome (midparentHeight)
ggplot(df_height_eda, aes(x = pred, y = midparentHeight)) +
geom_point() +
geom_abline()
##### MODEL TRAINING ----
#### Split dataset to train/test data ----
# Get the number of rows by using nrow to and store to N
N <- nrow(df_height)
# Show N
N
# Get 70% of N to split the dataset into 70% for training and the remaining 30% for testing
# Use floor() to get an integer
# Enclosing the whole variable declaration will print the value of the variable
(smp_size <- floor(0.70 * N))
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_height[train_indeces, ]
df_test <- df_height[-train_indeces, ]
# Use nrow() to examine df_height_train_train and df_height_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_height_train stats summary
summary(df_train)
# Create a formula to express childHeight as a function of midparentHeight: fmla and print it.
(fmla <- childHeight ~ midparentHeight)
# Step 3: Estimate a regression model
# Use lm() to build a model height_model from df_height_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
##### Load packages ----
# wage1 dataset can be obtained from this package
install.packages("wooldridge")
library(wooldridge)
##### Import data and store to df_wage ----
data(wage1)
# Explore more about the dataset
?wage1
# Store GaltonFamilies dataset to df_wage
df_wage <- wage1
##### MODEL TRAINING ----
#### Split dataset to train/test data ----
# Get the number of rows by using nrow to and store to N
N <- nrow(df_wage)
# Show N
N
# Get 70% of N to split the dataset into 70% for training and the remaining 30% for testing
# Use round() to get an integer
# Enclosing the whole variable declaration will print the value of the variable
(smp_size <- floor(0.70 * N))
# Set the seed to make your partition reproducible
set.seed(143)
train_indeces <- sample(seq_len(N), size = smp_size)
# Split dataset
df_train <- df_wage[train_indeces, ]
df_test <- df_wage[-train_indeces, ]
# Use nrow() to examine df_wage_train_train and df_wage_train_test
nrow(df_train)
nrow(df_test)
#### Train a model using the train data ----
# Show df_wage_train stats summary
summary(df_train)
# Create a formula to express wage as a function of educ: fmla and print it.
(fmla <- wage ~ educ)
# Use lm() to build a model height_model from df_wage_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
wage_pred <- -1.0683 + 0.56140 * 16
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
mae_train <- mean(abs(df_train$pred - df_train$wage))
mae_test <- mean(abs(df_test$pred - df_test$wage))
mse_train <- mean((df_train$pred - df_train$wage)^2)
mse_test <- mean((df_test$pred - df_test$wage)^2)
rmse_train <- RMSE(df_train$pred, df_train$wage)
rmse_test <- RMSE(df_test$pred, df_test$wage)
rsq_train <- cor(df_train$pred, df_train$wage)^2
rsq_test <- cor(df_test$pred, df_test$wage)^2
# Plot the predictions (on the x-axis) against the outcome (wage) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = wage)) +
geom_point() +
geom_abline() +
geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Wage (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
set.seed(143)
cv_results <- train(wage ~ educ, data = df_wage, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_mae <- cv_results$results$MAE
cv_mse <- cv_results$results$MSE
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("MAE (Train):", mae_train, "\n")
cat("MAE (Test):", mae_test, "\n")
cat("MSE (Train):", mse_train, "\n")
cat("MSE (Test):", mse_test, "\n\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("MAE (CV):", mean(cv_mae), "\n")
cat("MSE (CV):", mean(cv_mse), "\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
par(mfrow = c(2,2))
plot(height_model)
# install.packages("performance")
library(performance)
# Performance package:
performance::check_model(height_model)
# Create a formula to express wage as a function of educ: fmla and print it.
# Create a formula to express wage as a function of educ: fmla and print it.
(fmla <- wage ~ educ + exper)
# Use lm() to build a model height_model from df_wage_train that predicts the child's height from the parent's mid height
height_model <- lm(fmla, data = df_train)
# Use summary() to examine the model
summary(height_model)
# Manual prediction
wage_pred <- 18.09189 + 0.70359 * 69.020
# Evaluate model using Holdout Validation ----
df_train$pred <- predict(height_model, newdata = df_train)
df_test$pred <- predict(height_model, newdata = df_test)
# Load packages for regression evaluation
# install.packages("caret")
library(caret)
# Evaluation metrics
mae_train <- mean(abs(df_train$pred - df_train$wage))
mae_test <- mean(abs(df_test$pred - df_test$wage))
mse_train <- mean((df_train$pred - df_train$wage)^2)
mse_test <- mean((df_test$pred - df_test$wage)^2)
rmse_train <- RMSE(df_train$pred, df_train$wage)
rmse_test <- RMSE(df_test$pred, df_test$wage)
rsq_train <- cor(df_train$pred, df_train$wage)^2
rsq_test <- cor(df_test$pred, df_test$wage)^2
# Plot the predictions (on the x-axis) against the outcome (wage) on the test data
# Visualize predictions vs. actuals
ggplot(df_test, aes(x = pred, y = wage)) +
geom_point() +
geom_abline() +
geom_smooth(method = 'lm') +
labs(title = "Predicted vs Actual Wage (Test Set)")
# Cross-Validation Evaluation ----
# Using 5-fold Cross-Validation
set.seed(143)
cv_results <- train(wage ~ educ + exper, data = df_wage, method = "lm", trControl = trainControl(method = "cv", number = 5))
cv_mae <- cv_results$results$MAE
cv_mse <- cv_results$results$MSE
cv_rmse <- cv_results$results$RMSE
cv_rsq <- cv_results$results$Rsquared
# Summary
cat("Holdout Validation:\n")
cat("MAE (Train):", mae_train, "\n")
cat("MAE (Test):", mae_test, "\n")
cat("MSE (Train):", mse_train, "\n")
cat("MSE (Test):", mse_test, "\n\n")
cat("RMSE (Train):", rmse_train, "\n")
cat("RMSE (Test):", rmse_test, "\n")
cat("R-squared (Train):", rsq_train, "\n")
cat("R-squared (Test):", rsq_test, "\n\n")
cat("Cross-Validation:\n")
cat("MAE (CV):", mean(cv_mae), "\n")
cat("MSE (CV):", mean(cv_mse), "\n")
cat("RMSE (CV):", mean(cv_rmse), "\n")
cat("R-squared (CV):", mean(cv_rsq), "\n")
##### VISUALIZE THE MODEL ----
par(mfrow = c(2,2))
plot(height_model)
library(performance)
# Performance package:
performance::check_model(height_model)
# INTERPRETATION:
# 6.
# 6.
# 6.
# 6.
# 6.
